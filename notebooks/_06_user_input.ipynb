{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a user input and run it through the model that was saved in _05_mlp_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repository_root_directory:\t c:\\Users\\cengl\\Documents\\CSC 461\\code\\csc_461_fp\n",
      "repository_root_directory:\t already in path\n"
     ]
    }
   ],
   "source": [
    "#add the parent directory to the current working directory so that we can access MLP class\n",
    "repository_root_directory = os.path.dirname(os.getcwd())\n",
    "rrd = \"repository_root_directory:\\t\"\n",
    "print(rrd, repository_root_directory)\n",
    "\n",
    "if repository_root_directory not in sys.path:\n",
    "    sys.path.append(repository_root_directory)\n",
    "    print(rrd, \"added to path\")\n",
    "else:  \n",
    "    print(rrd, \"already in path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda status:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cengl\\AppData\\Local\\Temp\\ipykernel_1332\\186475717.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  savedModel = torch.load('model.pth')\n",
      "C:\\Users\\cengl\\AppData\\Local\\Temp\\ipykernel_1332\\186475717.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=30, out_features=256, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the class\n",
    "from mlp import MLP\n",
    "\n",
    "#check to see if cuda is avalable\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"cuda status: \", device)\n",
    "\n",
    "\n",
    "#create a configuration dictionary. input size is the number of features in each sample\n",
    "config = {\n",
    "    'input_size': 30,\n",
    "    'output_size': 10,\n",
    "    'hidden_layers': [256,64],\n",
    "    'batch_size': 64,\n",
    "    'n_epochs': 20,\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "\n",
    "model = MLP(config['input_size'], config['output_size'], config['hidden_layers']).to(device)\n",
    "#define criterion and an optimizer\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "# Load the saved state dictionary\n",
    "savedModel = torch.load('model.pth')\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "#model.load_state_dict(savedModel['model_state_dict'])\n",
    "#optimizer.load_state_dict(savedModel['optimizer_state_dict'])\n",
    "\n",
    "#startEpoch = savedModel['epoch']\n",
    "#lossValue = savedModel['loss']\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The absolute path is: c:\\Users\\cengl\\Documents\\CSC 461\\code\\csc_461_fp\\song1.mp3\n",
      "Current working directory: c:\\Users\\cengl\\Documents\\CSC 461\\code\\csc_461_fp\\notebooks\n",
      "y is:  [-9.8376831e-06 -2.1273676e-05 -3.0678435e-05 ... -3.1345972e-04\n",
      " -3.0257838e-04 -2.9095120e-04] sr is:  44100\n",
      "Data is:  [ 9.71570686e-02  4.05669370e-02  1.14922460e+03  1.04892204e+03\n",
      "  2.09968816e+03 -2.85636871e+02  2.02346115e+02 -2.25924473e+01\n",
      " -3.11582118e-01  1.41619005e+01 -6.03861284e+00 -1.48845530e+00\n",
      " -7.81741142e+00 -6.15064573e+00 -7.04260397e+00 -1.34700441e+01\n",
      " -6.61526585e+00 -4.52209520e+00  3.15452009e-01  2.97938824e-01\n",
      "  2.85389543e-01  4.01578158e-01  4.38602120e-01  3.42290670e-01\n",
      "  2.82668203e-01  3.34119618e-01  4.15963143e-01  3.53892475e-01\n",
      "  3.58989269e-01  3.21403474e-01]\n",
      "Predicted Genre: Classical\n",
      "output is:  tensor([[17.8418, 21.7945, 14.1225, 12.7982, 11.1918, 14.0066, 12.5498,  7.0805,\n",
      "         15.8143,  8.6845]], device='cuda:0')\n",
      "predicted class is:  1\n",
      "that class is:  Classical\n"
     ]
    }
   ],
   "source": [
    "#this will load a song and output the genre\n",
    "from data_preprocessor import DataPreprocessor\n",
    "from data_preprocessor_parallel_proc import DataPreprocessorParallelProc\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "\n",
    "sample_rate = 22050                     # default sample rate of the dataset\n",
    "preprocessor = DataPreprocessor()\n",
    "audioProcessor = DataPreprocessorParallelProc()\n",
    "\n",
    "#get the path to the file\n",
    "relative_path = Path('..') / 'song1.mp3'\n",
    "\n",
    "# Get the absolute path\n",
    "file_path = os.path.abspath(relative_path)\n",
    "\n",
    "print(f\"The absolute path is: {file_path}\")\n",
    "\n",
    "print('Current working directory:', os.getcwd())\n",
    "\n",
    "# Preprocess the audio\n",
    "try:\n",
    "            # Load the audio file with the correct sample rate\n",
    "            y, sr = librosa.load(file_path, sr=sample_rate) if sample_rate != 22050 else librosa.load(file_path, sr=None)\n",
    "\n",
    "            # Normalize the audio\n",
    "            y = librosa.util.normalize(y)\n",
    "\n",
    "            # Trim leading and trailing silence\n",
    "            y, _ = librosa.effects.trim(y)\n",
    "\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error preprocessing file {file_path}: {e}\")\n",
    "print(\"y is: \", y, \"sr is: \", sr)\n",
    "\n",
    "\n",
    "#extract the features\n",
    "from features_extractor import FeaturesExtractor\n",
    "\n",
    "feature_extractor = FeaturesExtractor()\n",
    "data = feature_extractor.extract_features_from_file(y,sr)\n",
    "print(\"Data is: \",data)\n",
    "\n",
    "#convert the data to a tensor\n",
    "features = torch.tensor(data, dtype=torch.float32).unsqueeze(0) #make the data a tensor\n",
    "features = features.to(device) #make sure that it is using the same device. \n",
    "\n",
    "#run the data through the model and get the predicted genre\n",
    "with torch.no_grad():  # No gradients needed for inference\n",
    "\n",
    "    output = model(features)  # Forward pass\n",
    "    predicted_class = torch.argmax(output, dim=1).item() \n",
    "\n",
    "\n",
    "genre_mapping = {0: 'blues', 1: 'Classical', 2: 'Country', 3: 'disco',4: 'hiphop', 5: 'jazz', 6: 'metal', 7: 'pop',8: 'reggae', 9: 'rock'}  # Adjust based on your data\n",
    "predicted_genre = genre_mapping[predicted_class]\n",
    "print(f\"Predicted Genre: {predicted_genre}\")\n",
    "\n",
    "print(\"output is: \", output)\n",
    "print(\"predicted class is: \", predicted_class)\n",
    "print(\"that class is: \", predicted_genre)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
